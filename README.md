# Gesture to Speech: Enabling Communication for the Speech-Impaired

A deep learning-based system that translates hand gestures into audible speech, aiming to bridge communication gaps for individuals with speech impairments.

## Features

- Real-time gesture recognition using webcam input
- Speech output using text-to-speech synthesis
- Support for both alphabets and dynamic gestures
- Intuitive web interface using Flask, HTML/CSS, and JavaScript
- Custom-trained CNN and 3D CNN models
- Works offline after initial setup

## Technologies Used

- Python, Flask
- OpenCV for gesture input capture
- TensorFlow/Keras for model training and inference
- Text-to-Speech (pyttsx3 or gTTS)
- HTML/CSS/JavaScript for frontend
- Apache 2.0 Licensed

## ğŸ“ Project Structure

Gesture-to-Speech/

â”œâ”€â”€ app.py

â”œâ”€â”€ models/

â”‚ â”œâ”€â”€ mobilenet_model.h5

â”‚ â””â”€â”€ isl_3dcnn_model.h5

â”œâ”€â”€ static/

â”‚ â”œâ”€â”€ videos/

â”‚ â””â”€â”€ style.css

â”œâ”€â”€ templates/

â”‚ â”œâ”€â”€ index.html

â”‚ â”œâ”€â”€ video.html

â”‚ â”œâ”€â”€ main.html

â”‚ â””â”€â”€ to_gest.html

â”œâ”€â”€ dataset/

â”‚ â”œâ”€â”€ AlphNum/

â”‚ â””â”€â”€ gestures/

â”œâ”€â”€ class_indices.json

â””â”€â”€ README.md
